{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90254a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import fetch_competitions, request_headers, Historize, commit_changes, createDetailedURL, polite_request\n",
    "from sql_shortcuts import table, append_table, load_keys, drop_table, tables, replace_table\n",
    "from datetime import datetime, timedelta\n",
    "from bs4 import BeautifulSoup\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import hashlib\n",
    "import requests\n",
    "import time\n",
    "import random\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4527189a",
   "metadata": {},
   "source": [
    "### Leagues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3083068",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-02 19:22:58,581 - INFO - FETCHING LEAGUES\n",
      "2025-06-02 19:23:00,324 - INFO - League table up-to-date\n"
     ]
    }
   ],
   "source": [
    "# Load retrieved league data\n",
    "logging.info(\"FETCHING LEAGUES\")\n",
    "leagues_history = table(\"b1_league\")\n",
    "\n",
    "# Scrape new league data\n",
    "league_data = fetch_competitions()\n",
    "leagues =  pd.DataFrame(league_data, columns =  ['name', 'league_link'])\n",
    "leagues = pd.merge(leagues.assign(joined =  1), leagues_history, on =  ['name', 'league_link'], how = 'outer')\n",
    "leagues = leagues[leagues.joined != 1]\n",
    "\n",
    "#Update b1_league\n",
    "if len(leagues > 0):\n",
    "    logging.info(f\"Committing {len(leagues)} league records\")\n",
    "    leagues = leagues.drop(\"joined\", axis = 1)\n",
    "    append_table(leagues, league)\n",
    "else:\n",
    "    logging.info(\"League table up-to-date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e2b902",
   "metadata": {},
   "source": [
    "### Clubs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2bd483f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-02 19:23:00,363 - INFO - FETCHING CLUBS\n",
      "2025-06-02 19:23:07,476 - INFO - Successfully retrieved https://www.transfermarkt.com/premier-league/startseite/wettbewerb/GB1\n",
      "2025-06-02 19:23:13,138 - INFO - Successfully retrieved https://www.transfermarkt.com/laliga/startseite/wettbewerb/ES1\n",
      "2025-06-02 19:23:19,708 - INFO - Successfully retrieved https://www.transfermarkt.com/bundesliga/startseite/wettbewerb/L1\n",
      "2025-06-02 19:23:26,771 - INFO - Successfully retrieved https://www.transfermarkt.com/serie-a/startseite/wettbewerb/IT1\n",
      "2025-06-02 19:23:32,564 - INFO - Successfully retrieved https://www.transfermarkt.com/ligue-1/startseite/wettbewerb/FR1\n",
      "2025-06-02 19:23:38,634 - INFO - Successfully retrieved https://www.transfermarkt.com/liga-portugal/startseite/wettbewerb/PO1\n",
      "2025-06-02 19:23:44,567 - INFO - Successfully retrieved https://www.transfermarkt.com/eredivisie/startseite/wettbewerb/NL1\n",
      "2025-06-02 19:23:51,139 - INFO - Successfully retrieved https://www.transfermarkt.com/jupiler-pro-league/startseite/wettbewerb/BE1\n",
      "2025-06-02 19:24:00,936 - INFO - Successfully retrieved https://www.transfermarkt.com/super-liga-srbije/startseite/wettbewerb/SER1\n",
      "2025-06-02 19:24:08,181 - INFO - Successfully retrieved https://www.transfermarkt.com/super-league-1/startseite/wettbewerb/GR1\n",
      "2025-06-02 19:24:15,013 - INFO - Successfully retrieved https://www.transfermarkt.com/allsvenskan/startseite/wettbewerb/SE1\n",
      "2025-06-02 19:24:39,026 - INFO - Successfully retrieved https://www.transfermarkt.com/supersport-hnl/startseite/wettbewerb/KR1 on attempt 2\n",
      "2025-06-02 19:25:03,126 - INFO - Successfully retrieved https://www.transfermarkt.com/major-league-soccer/startseite/wettbewerb/MLS1 on attempt 2\n",
      "2025-06-02 19:25:09,569 - INFO - Successfully retrieved https://www.transfermarkt.com/campeonato-brasileiro-serie-a/startseite/wettbewerb/BRA1\n",
      "2025-06-02 19:26:37,374 - INFO - Successfully retrieved https://www.transfermarkt.com/torneo-apertura/startseite/wettbewerb/ARG1 on attempt 4\n",
      "2025-06-02 19:27:01,285 - INFO - Successfully retrieved https://www.transfermarkt.com/liga-mx-apertura/startseite/wettbewerb/MEXA on attempt 2\n",
      "2025-06-02 19:27:07,816 - INFO - Successfully retrieved https://www.transfermarkt.com/persian-gulf-pro-league/startseite/wettbewerb/IRN1\n",
      "2025-06-02 19:27:12,783 - INFO - Successfully retrieved https://www.transfermarkt.com/qatar-stars-league/startseite/wettbewerb/QSL\n",
      "2025-06-02 19:27:17,455 - INFO - Successfully retrieved https://www.transfermarkt.com/liga-1-indonesia/startseite/wettbewerb/IN1L\n",
      "2025-06-02 19:27:45,345 - INFO - Successfully retrieved https://www.transfermarkt.com/j1-league/startseite/wettbewerb/JAP1 on attempt 2\n",
      "2025-06-02 19:27:51,265 - INFO - Successfully retrieved https://www.transfermarkt.com/egyptian-premier-league/startseite/wettbewerb/EGY1\n",
      "2025-06-02 19:28:37,634 - INFO - Successfully retrieved https://www.transfermarkt.com/betway-premiership/startseite/wettbewerb/SFA1 on attempt 3\n",
      "2025-06-02 19:28:44,699 - INFO - Successfully retrieved https://www.transfermarkt.com/botola-pro-inwi/startseite/wettbewerb/MAR1\n",
      "2025-06-02 19:28:53,368 - INFO - Successfully retrieved https://www.transfermarkt.com/ligue-professionnelle-1/startseite/wettbewerb/TUN1\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"FETCHING CLUBS\")\n",
    "\n",
    "leagues = table(\"b1_league\")\n",
    "league_urls = list(leagues.league_link.unique())\n",
    "club_df = pd.DataFrame()\n",
    "b2_failures = []\n",
    "\n",
    "\n",
    "#Scrape clubs\n",
    "for url in league_urls:\n",
    "\n",
    "    response = polite_request(url)\n",
    "    if not isinstance(response, str):\n",
    "        data = pd.read_html(StringIO(response.text))\n",
    "        df = [i for i in data if 'total market value' in str(i).lower()][0]\n",
    "        df[\"league_link\"] = url\n",
    "        club_df = pd.concat([club_df, df])\n",
    "    else:\n",
    "        b2_failures.append(url)\n",
    "\n",
    "# deduplicate, clean columns\n",
    "club_df = club_df.reset_index(drop = True)\n",
    "club_df = club_df.dropna(subset = 'Club.1')\n",
    "selection = ['Club.1', 'league_link']\n",
    "club_df = club_df[selection].drop_duplicates().rename({\"Club.1\" : \"club\"}, axis = 1)\n",
    "\n",
    "if len(b2_failures)>0:\n",
    "    logging.error(f\"b2_club failures: {b2_failures}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eac75436",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-02 19:28:53,630 - INFO - Adding 0 records to b2_club\n",
      "2025-06-02 19:28:53,632 - INFO - 0 records being updated - effective_end_date == 2025-06-01\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continue? (y/n)\n",
      "y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-02 19:32:36,786 - INFO - Update and append complete (b2_club)\n"
     ]
    }
   ],
   "source": [
    "processor = Historize(\n",
    "    club_df,\n",
    "    primary_key = ['league_link', 'club']\n",
    ")\n",
    "\n",
    "processor.run()\n",
    "\n",
    "club_updates = processor.df\n",
    "\n",
    "club_updates['last_updated'] = datetime.today()\n",
    "club_updates = club_updates.rename({\"ID\": \"club_id\"}, axis = 1)\n",
    "selection = [\"club_id\", 'club', 'league_link', 'hash_key', 'effective_start_date', 'effective_end_date', 'last_updated']\n",
    "club_updates = club_updates[selection] \n",
    "\n",
    "commit_changes(\n",
    "    df = club_updates, \n",
    "    table_name = 'b2_club', \n",
    "    primary_key= 'club_id'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133cdd3b",
   "metadata": {},
   "source": [
    "### Club Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82b641e3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-02 19:32:36,810 - INFO - FETCHING CLUB LINKS\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"FETCHING CLUB LINKS\")\n",
    "league_urls = table('b2_club')['league_link'].unique()\n",
    "club_links = []\n",
    "\n",
    "for idx, league_url in enumerate(league_urls):\n",
    "        \n",
    "    response = requests.get(league_url, headers=request_headers)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Find the table containing the teams\n",
    "    temp = soup.select('table.items tbody tr')\n",
    "    for row in soup.select('table.items tbody tr'):\n",
    "        link_tag = row.select_one('td.hauptlink a')\n",
    "        if link_tag:\n",
    "            club_name = link_tag.text.strip()\n",
    "            relative_link = link_tag['href']\n",
    "            #filter out top scorer links\n",
    "            if r\"profil/spieler\" not in relative_link:\n",
    "                full_link = \"https://www.transfermarkt.com\" + relative_link\n",
    "                club_links.append((league_url, club_name, full_link))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71adc164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deduplicate / filter links\n",
    "club_links_df = pd.DataFrame(club_links, columns = ['league_link', 'club', 'club_link'])\n",
    "club_links_df = club_links_df[club_links_df.club_link.str.contains(\"start\")] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4b48af5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "processor = Historize(\n",
    "    club_links_df,\n",
    "    primary_key = ['league_link', 'club']\n",
    ")\n",
    "\n",
    "processor.run()\n",
    "updates = processor.df\n",
    "updates['last_updated'] = datetime.today()\n",
    "updates = updates.rename({\"ID\": \"club_link_id\"}, axis = 1)\n",
    "selection = ['club_link_id', 'league_link', 'club', 'club_link', 'hash_key', 'effective_start_date', 'effective_end_date', 'last_updated']\n",
    "updates = updates[selection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03e146b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-02 19:35:09,613 - INFO - Adding 12 records to b3_club_link\n",
      "2025-06-02 19:35:09,615 - INFO - 12 records being updated - effective_end_date == 2025-06-01\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continue? (y/n)\n",
      "y\n"
     ]
    },
    {
     "ename": "OperationalError",
     "evalue": "table b3_club_link has no column named last_updated",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mcommit_changes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mupdates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtable_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mb3_club_link\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprimary_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclub_link_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[0;32m      5\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\ds\\transfermarkt-monitor\\src\\utilities.py:182\u001b[0m, in \u001b[0;36mcommit_changes\u001b[1;34m(df, table_name, primary_key, db_path)\u001b[0m\n\u001b[0;32m    179\u001b[0m         cursor\u001b[38;5;241m.\u001b[39mexecute(update_query, (yesterday, key))\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;66;03m# Append new records\u001b[39;00m\n\u001b[1;32m--> 182\u001b[0m     \u001b[43mupdate_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtable_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mappend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    184\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpdate and append complete (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtable_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\citynet\\lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\citynet\\lib\\site-packages\\pandas\\core\\generic.py:3087\u001b[0m, in \u001b[0;36mNDFrame.to_sql\u001b[1;34m(self, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[0m\n\u001b[0;32m   2889\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2890\u001b[0m \u001b[38;5;124;03mWrite records stored in a DataFrame to a SQL database.\u001b[39;00m\n\u001b[0;32m   2891\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3083\u001b[0m \u001b[38;5;124;03m[(1,), (None,), (2,)]\u001b[39;00m\n\u001b[0;32m   3084\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[0;32m   3085\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sql\n\u001b[1;32m-> 3087\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_sql\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3088\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3089\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3090\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3091\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3092\u001b[0m \u001b[43m    \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3093\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3094\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3095\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3096\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3097\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3098\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\citynet\\lib\\site-packages\\pandas\\io\\sql.py:842\u001b[0m, in \u001b[0;36mto_sql\u001b[1;34m(frame, name, con, schema, if_exists, index, index_label, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[0;32m    837\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    838\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mframe\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m argument should be either a Series or a DataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    839\u001b[0m     )\n\u001b[0;32m    841\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pandasSQL_builder(con, schema\u001b[38;5;241m=\u001b[39mschema, need_transaction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m pandas_sql:\n\u001b[1;32m--> 842\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pandas_sql\u001b[38;5;241m.\u001b[39mto_sql(\n\u001b[0;32m    843\u001b[0m         frame,\n\u001b[0;32m    844\u001b[0m         name,\n\u001b[0;32m    845\u001b[0m         if_exists\u001b[38;5;241m=\u001b[39mif_exists,\n\u001b[0;32m    846\u001b[0m         index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m    847\u001b[0m         index_label\u001b[38;5;241m=\u001b[39mindex_label,\n\u001b[0;32m    848\u001b[0m         schema\u001b[38;5;241m=\u001b[39mschema,\n\u001b[0;32m    849\u001b[0m         chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[0;32m    850\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    851\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m    852\u001b[0m         engine\u001b[38;5;241m=\u001b[39mengine,\n\u001b[0;32m    853\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mengine_kwargs,\n\u001b[0;32m    854\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\citynet\\lib\\site-packages\\pandas\\io\\sql.py:2851\u001b[0m, in \u001b[0;36mSQLiteDatabase.to_sql\u001b[1;34m(self, frame, name, if_exists, index, index_label, schema, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[0;32m   2841\u001b[0m table \u001b[38;5;241m=\u001b[39m SQLiteTable(\n\u001b[0;32m   2842\u001b[0m     name,\n\u001b[0;32m   2843\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2848\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   2849\u001b[0m )\n\u001b[0;32m   2850\u001b[0m table\u001b[38;5;241m.\u001b[39mcreate()\n\u001b[1;32m-> 2851\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\citynet\\lib\\site-packages\\pandas\\io\\sql.py:1119\u001b[0m, in \u001b[0;36mSQLTable.insert\u001b[1;34m(self, chunksize, method)\u001b[0m\n\u001b[0;32m   1116\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1118\u001b[0m chunk_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m(arr[start_i:end_i] \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m data_list))\n\u001b[1;32m-> 1119\u001b[0m num_inserted \u001b[38;5;241m=\u001b[39m \u001b[43mexec_insert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;66;03m# GH 46891\u001b[39;00m\n\u001b[0;32m   1121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_inserted \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\citynet\\lib\\site-packages\\pandas\\io\\sql.py:2547\u001b[0m, in \u001b[0;36mSQLiteTable._execute_insert\u001b[1;34m(self, conn, keys, data_iter)\u001b[0m\n\u001b[0;32m   2545\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_execute_insert\u001b[39m(\u001b[38;5;28mself\u001b[39m, conn, keys, data_iter) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[0;32m   2546\u001b[0m     data_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(data_iter)\n\u001b[1;32m-> 2547\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecutemany\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert_statement\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_rows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2548\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mrowcount\n",
      "\u001b[1;31mOperationalError\u001b[0m: table b3_club_link has no column named last_updated"
     ]
    }
   ],
   "source": [
    "commit_changes(\n",
    "    df = updates, \n",
    "    table_name = 'b3_club_link', \n",
    "    primary_key='club_link_id'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839ee5fd",
   "metadata": {},
   "source": [
    "### Players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29515ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"FETCHING PLAYERS\")\n",
    "club_links = table(\"b3_club_link\")\n",
    "club_links[\"club_link_detailed\"] = club_links['club_link'].apply(lambda x: createDetailedURL(x))\n",
    "urls = club_links.club_link_detailed.unique()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "conn = sqlite3.connect(\"transfermarkt.db\")\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"DROP TABLE IF EXISTS b4_player_staging\")\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "b4_failures = []\n",
    "for idx, url in enumerate(urls):\n",
    "    \n",
    "    response = polite_request(url)\n",
    "\n",
    "    if not isinstance(response, str):\n",
    "        data = pd.read_html(StringIO(response.text))\n",
    "        players = [i for i in data if 'Contract' in i.columns][0].dropna(subset = \"#\").copy()\n",
    "        players['club_link_detailed'] = url\n",
    "        logging.info(f\"Adding {len(players)} to staging: {url}\")\n",
    "        append_table(players, \"b4_player_staging\")\n",
    "        \n",
    "    else:\n",
    "        b4_failures.append(url)\n",
    "        \n",
    "logging.info(f\"{round((time.time() - start_time)/60)} minutes to process\")\n",
    "\n",
    "if len(b4_failures)>0:\n",
    "    logging.error(f\"b4_player failures: {b4_failures}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8183b5cb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for idx, url in enumerate(new_urls):\n",
    "    \n",
    "    response = polite_request(url)\n",
    "\n",
    "    if not isinstance(response, str):\n",
    "        data = pd.read_html(StringIO(response.text))\n",
    "        players = [i for i in data if 'Contract' in i.columns][0].dropna(subset = \"#\").copy()\n",
    "        players['club_link_detailed'] = url\n",
    "        logging.info(f\"Adding {len(players)} to staging: {url}\")\n",
    "        append_table(players, \"b4_player_staging\")\n",
    "        \n",
    "    else:\n",
    "        b4_failures.append(url)\n",
    "        \n",
    "logging.info(f\"{round((time.time() - start_time)/60)} minutes to process\")\n",
    "\n",
    "if len(b4_failures)>0:\n",
    "    logging.error(f\"b4_player failures: {b4_failures}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d3a670",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Staging cleaning\n",
    "players = table(\"b4_player_staging\")\n",
    "players = players.dropna(subset = \"#\")\n",
    "mapping = {'#':'number', 'Date of birth/Age':'age'}\n",
    "players = players.rename(mapping, axis = 1)\n",
    "players.columns = [i.lower().strip().replace(\" \", \"_\") for i in players.columns]\n",
    "players = players.drop([\"nat.\", \"signed_from\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab889e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "player_historizer = Historize(\n",
    "    players,\n",
    "    primary_key = ['player', 'club_link_detailed']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11ab273",
   "metadata": {},
   "outputs": [],
   "source": [
    "player_historizer.run()\n",
    "player_updates = player_historizer.df\n",
    "player_updates = player_updates.rename({\"ID\": \"player_id\"}, axis = 1)\n",
    "player_updates['last_updated'] = datetime.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6112ae13",
   "metadata": {},
   "outputs": [],
   "source": [
    "commit_changes(\n",
    "    df = player_updates, \n",
    "    table_name = 'b4_player', \n",
    "    primary_key='player_id'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
